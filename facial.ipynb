{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Path for face image database\u001b[39;00m\n\u001b[0;32m      7\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m recognizer \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mface\u001b[39m.\u001b[39mLBPHFaceRecognizer_create()\n\u001b[0;32m      9\u001b[0m detector \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(\u001b[39m\"\u001b[39m\u001b[39mfrontalface.xml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39m# function to get the images and label data\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path for face image database\n",
    "path = 'dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"frontalface.xml\")\n",
    "\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')        \n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "\n",
    "print(path)\n",
    "\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer.yml') \n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Initializing face capture. Look the camera and wait ...\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier('frontalface.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # set Width\n",
    "cap.set(4,480) # set Height\n",
    "\n",
    "\n",
    "# For each person, enter one numeric face id\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "# Initialize individual sampling face count\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,     \n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,     \n",
    "        minSize=(20, 20)\n",
    "    )\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        count += 1\n",
    "        print(count)\n",
    "        \n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"dataset/\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        \n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]  \n",
    "    cv2.imshow('video',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 80: # Take 40 face sample and stop video\n",
    "         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
